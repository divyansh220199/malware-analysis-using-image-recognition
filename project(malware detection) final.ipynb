{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"project(malware detection) final.ipynb","provenance":[],"collapsed_sections":["BfEdRc1GyZry","B6M80963yZsP","lL8kcctRyZsc","vXr8JnGc_Cn2"],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BfEdRc1GyZry","colab_type":"text"},"source":["# Extracting .bytes files from 7zip file and placing them acc. to class in folders"]},{"cell_type":"code","metadata":{"id":"e8-ctk4MyZrz","colab_type":"code","colab":{}},"source":["## getting name of files of specified class\n","\n","def get_file_name(class_no):\n","    \n","    df = pd.read_csv(file_name_with_class_name) ## reading the Y_train\n","    \n","    class1_files = df[df['Class'] == class_no] ##getting rows with specified class\n","    class1_files_names = class1_files['Id']  ## getting column with name of files\n","\n","    class1_files_names = class1_files_names.values ## getting numpy of the column with name\n","\n","    class1_files_names = class1_files_names + '.bytes' ## adding extension to  the file name\n","    return class1_files_names ## returning the name of files with extension of specified class "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rug3px5lyZr2","colab_type":"code","colab":{}},"source":["## this method allow us tot extract the file of a specified class to a specified location\n","import py7zr\n","\n","def get_extracted_files(class_no, path_to_extract_file):\n","    \n","    print('Extracting.....')\n","    \n","    file_names_of_specified_class = get_file_name(class_no) ## getting the file_names of the req class\n","    \n","    with py7zr.SevenZipFile(microsoft_dataset_7z_file,'r') as zip_file:\n","        zip_file.extract(path =path_to_extract_file , targets = file_names_of_specified_class)\n","    \n","    print('Extracting Complete.....')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"knTqnnWhyZr5","colab_type":"code","colab":{}},"source":["##extracting the files into respective class_folders\n","\n","## path of .7z file to be extracted\n","microsoft_dataset_7z_file = r'F:\\malware dataset\\microsoft dataset\\train.7z'\n","\n","## path of class folders\n","path_to_file_class1 = r'E:\\project malware detection\\malware files\\class1'\n","path_to_file_class2 = r'E:\\project malware detection\\malware files\\class2'\n","\n","## y_train path to get file names of repective class\n","file_name_with_class_name = r'F:\\malware dataset\\microsoft dataset\\trainLabels.csv'\n","\n","## calling the fuction giving it the class req and paths to extract files to respective class folder\n","get_extracted_files(1,path_to_file_class1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OXZUPYsnyZr7","colab_type":"text"},"source":["## Organizing extracted .bytes file acc. to the class folders"]},{"cell_type":"code","metadata":{"id":"0hcPwG7QyZr7","colab_type":"code","colab":{}},"source":["## getting name of files of specified class\n","\n","import pandas as pd\n","import numpy as np\n","\n","def get_file_name(class_no):\n","    \n","    df = pd.read_csv(file_name_with_class_name) ## reading the Y_train\n","    \n","    class1_files = df[df['Class'] == class_no] ##getting rows with specified class\n","    class1_files_names = class1_files['Id']  ## getting column with name of files\n","\n","    class1_files_names = class1_files_names.values ## getting numpy of the column with name\n","\n","    class1_files_names = class1_files_names + '.bytes' ## adding extension to  the file name\n","    return class1_files_names ## returning the name of files with extension of specified class "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kN1b4a5DyZr_","colab_type":"code","colab":{}},"source":["# copying files of a specific class given to its folder\n","import shutil\n","def organize_dataset(class_no, microsoft_dataset_extracted, path_to_class_folder):\n","    \n","    print('Organizing.....')\n","    \n","    file_names_of_specified_class = get_file_name(class_no) ## getting the file_names of the req class\n","    \n","    for file_name in file_names_of_specified_class:\n","        shutil.copyfile(microsoft_dataset_extracted + r'\\\\' + file_name, path_to_class_folder + r'\\\\' + file_name)\n","                                                                            ##copting each file from source to dest\n","    print('Organizing Complete.....')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LjWCbO_GyZsC","colab_type":"code","outputId":"be2a070f-c381-4465-b674-d66203c42f9a","colab":{}},"source":["## getting the data organized by arranging the each file in its class folder\n","\n","## path of folder having extraceted file\n","microsoft_dataset_extracted = r'F:\\malware dataset\\microsoft dataset\\train' \n","\n","## path of class folders\n","path_to_class_folder = r'E:\\project malware detection\\malware files'\n","\n","## y_train path to get file names of repective class\n","file_name_with_class_name = r'F:\\malware dataset\\microsoft dataset\\trainLabels.csv'\n","\n","\n","## calling the fuction giving it the class req and paths of source and dest to copy files to respective class folder\n","\n","class_folder_name = r'\\class1'\n","class_no = 1\n","\n","organize_dataset(class_no, microsoft_dataset_extracted, path_to_class_folder + class_folder_name)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Copying.....\n","Copying Complete.....\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"slggyYSOyZsF","colab_type":"text"},"source":["## converting files in a folder to binary "]},{"cell_type":"code","metadata":{"id":"a0ZTYpjhyZsG","colab_type":"code","colab":{}},"source":["## this method will give us the binary of respective file with filling the blank values\n","\n","import pandas as pd\n","import numpy as np\n","\n","def get_refined_data_txt(file , dest_folder, file_name_to_save, **arg):\n","    df = pd.read_csv(file, delimiter = ' ', header=None, low_memory=False )         ## reading the file\n","\n","    if(arg['offset'] == True):  ## checking if we have to keep offset\n","        \n","        for i in range(1,17):                    ## filling NAN values in all columns and replacing them with 00\n","            df[i].fillna('00', inplace = True)\n","        \n","        binary_numpy = df.values               ##converting dataframe to numpy array                           \n","       \n","        with open(dest_folder + file_name_to_save + r'.txt','w') as file:   ## making a txt file\n","            file.write('')\n","        with open(dest_folder + file_name_to_save + r'.txt','a') as file:   ## reading the file we made and writing the values in it one by one\n","            for row in binary_numpy:\n","                single_line = ''\n","                for binary in row:\n","                    single_line = single_line + str(binary) + ' '  ## converting no to string so that it can be written in file\n","                file.write(single_line)\n","                file.write(chr(10))\n","\n","    elif(arg['offset'] == False): ## checking if we want to remove offset\n","        \n","        df.drop(0, axis=1, inplace = True)   ## removing offset\n","        \n","        for i in range(1,17):                ## filling NAN values in all columns and replacing them with 00 \n","            df[i].fillna('00', inplace = True)\n","        \n","        binary_numpy = df.values              ##converting dataframe to numpy array\n","        \n","        with open(dest_folder + file_name_to_save + r'.txt','w') as file:  ## making a txt file\n","            file.write('')\n","        with open(dest_folder + file_name_to_save + r'.txt','a') as file:   ## reading the file we made and writing the values in it one by one\n","            for row in binary_numpy:\n","                single_line = ''\n","                for binary in row:\n","                    single_line = single_line + str(binary) + ' '  ## converting no to string so that it can be written in file\n","                file.write(single_line)\n","                file.write(chr(10))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K0kxd7yvyZsJ","colab_type":"code","colab":{}},"source":["## this method will give us the binary file of all the files in the folder\n","\n","import glob\n","\n","def making_binary_txt(source_folder,dest_folder,**arg):\n","    files_in_source_folder = glob.glob(source_folder + r'\\*.BYTES') ## reading all the bytes files in the folder\n","    \n","    file_no = 0             ## initializing the file_no\n","    print('Converting to binary....')\n","    for file in files_in_source_folder:\n","        \n","        if(arg[\"offset\"] == True):\n","            get_refined_data_txt(file , dest_folder, file_name_to_save_with_offset +str(file_no), **arg) ## getting binary of a file\n","            \n","        elif(arg[\"offset\"] == False):\n","            get_refined_data_txt(file , dest_folder, file_name_to_save_without_offset +str(file_no), **arg) ## getting binary of a file\n","            \n","        file_no = file_no + 1  ## incrementing the file no\n","    print('Converted to binary....')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VgJ3tJbyZsL","colab_type":"code","colab":{}},"source":["## path of source folder\n","source_folder_byte_file = r'E:\\project malware detection\\malware files'\n","\n","## path of dest_folder for saving txt with and without offset\n","dest_folder_txt_with_offset = r'E:\\project malware detection\\txt malware files\\txt malware files with offset'\n","dest_folder_txt_without_offset = r'E:\\project malware detection\\txt malware files\\txt malware files without offset'\n","\n","## file name to give binary txt files with and without offset\n","file_name_to_save_with_offset = r'\\file Offset'\n","file_name_to_save_without_offset = r'\\file without Offset'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KhRiSFWtyZsN","colab_type":"code","colab":{}},"source":["## calling the function to get both type of txt's with and without offset with no NAN values \n","folder_of_class_to_be_converted = '\\class2'\n","\n","making_binary_txt(source_folder_byte_file + folder_of_class_to_be_converted, dest_folder_txt_without_offset + folder_of_class_to_be_converted, offset = False)\n","\n","making_binary_txt(source_folder_byte_file + folder_of_class_to_be_converted, dest_folder_txt_with_offset + folder_of_class_to_be_converted, offset = True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B6M80963yZsP","colab_type":"text"},"source":["# Converting files to images of the format specified"]},{"cell_type":"markdown","metadata":{"id":"GIzMg_1ByZsQ","colab_type":"text"},"source":["## Creating color map\n"]},{"cell_type":"code","metadata":{"id":"r6GA_hE1zOtU","colab_type":"code","colab":{}},"source":["'''color_map = []\n","import cv2\n","img = cv2.imread('256colour.png')\n","#cv2.imshow('img',img)\n","img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","for i in range(4,64,8):\n","    for j in range(4,128,8):\n","        color_map.append(img[i][j])\n","for i in range(4,64,8):\n","    for j in range(132,256,8):\n","        color_map.append(img[i][j])\n","#img = img/255\n","print(img.shape)\n","title = ['title']\n","x = [img]\n","for i in range(1):\n","    plt.subplot(1,1,i+1), plt.imshow(x[i])\n","    plt.title(title[i])\n","    plt.xticks([]),plt.yticks([])\n","cv2.waitKey(0) & 0xFF\n","cv2.destroyAllWindows()\n","color_map1 = np.array(color_map)'''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J_w_pwXZyZsQ","colab_type":"code","colab":{}},"source":["## 2D COLOR MAP\n","\n","color_map = np.array([[[  0,   0,   0],[  0,   0,  85],[  0,   0, 170],[  0,   0, 255],[ 36,   0,   0],[ 36,   0,  85],\n","              [ 36, 0, 170],[ 36,   0, 255],[ 72,   0,   0],[ 72,   0,  85],[ 72,   0, 170],[ 72,   0, 255],\n","              [108, 0, 0],[108,   0,  85],[108,   0, 170],[108,   0, 255]],\n","             [[  0,  36,   0],[  0,  36,  85],[  0,  36, 170],[  0,  36, 255],[ 36,  36,   0],[ 36,  36,  85],[ 36,  36, 170],\n","              [ 36,  36, 255],[ 72,  36,   0],[ 72,  36,  85],[ 72,  36, 170],[ 72,  36, 255],[108,  36,   0],[108,  36,  85],\n","              [108,  36, 170],[108,  36, 255]],\n","             [[  0,  72,   0],[  0,  72,  85],[  0,  72, 170],[  0,  72, 255],[ 36,  72,   0],[ 36,  72,  85],[ 36,  72, 170],\n","              [ 36,  72, 255],[ 72,  72,   0],[ 72,  72,  85],[ 72,  72, 170],[ 72,  72, 255],[108,  72,   0],[108,  72,  85],\n","              [108,  72, 170],[108,  72, 255]],\n","             [[  0, 108,   0],[  0, 108,  85],[  0, 108, 170],[  0, 108, 255],[ 36, 108,   0],[ 36, 108,  85],[ 36, 108, 170],\n","              [ 36, 108, 255],[ 72, 108,   0],[ 72, 108,  85],[ 72, 108, 170],[ 72, 108, 255],[108, 108,   0],[108, 108,  85],\n","              [108, 108, 170],[108, 108, 255]],\n","             [[  0, 144,   0],[  0, 144,  85],[  0, 144, 170],[  0, 144, 255],[ 36, 144,   0],[ 36, 144,  85],[36, 144, 170],\n","              [ 36, 144, 255],[ 72, 144,   0],[ 72, 144,  85],[ 72, 144, 170],[ 72, 144, 255],[108, 144,   0],[108, 144,  85],\n","              [108, 144, 170],[108, 144, 255]],\n","             [[  0, 180,   0],[  0, 180,  85],[  0, 180, 170],[  0, 180, 255],[ 36, 180,   0],[ 36, 180,  85],[ 36, 180, 170],\n","              [ 36, 180, 255],[ 72, 180,   0],[ 72, 180,  85],[ 72, 180, 170],[ 72, 180, 255],[108, 180,   0],[108, 180,  85],\n","              [108, 180, 170],[108, 180, 255]],\n","             [[  0, 216,   0],[  0, 216,  85],[  0, 216, 170],[  0, 216, 255],[ 36, 216,   0],[ 36, 216,  85],[ 36, 216, 170],\n","              [ 36, 216, 255],[ 72, 216,   0],[ 72, 216,  85],[ 72, 216, 170],[ 72, 216, 255],[108, 216,   0],[108, 216,  85],\n","              [108, 216, 170],[108, 216, 255]],\n","             [[  0, 252,   0],[  0, 252,  85],[  0, 252, 170],[  0, 252, 255],[ 36, 252,   0],[ 36, 252,  85],[ 36, 252, 170],\n","              [36, 252, 255],[ 72, 252,   0],[ 72, 252,  85],[ 72, 252, 170],[ 72, 252, 255],[108, 252,   0],[108, 252,  85],\n","              [108, 252, 170],[108, 252, 255]],\n","             [[144,   0,   0],[144,   0,  85],[144,   0, 170],[144,   0, 255],[180,   0,   0],[180,   0,  85],[180,   0, 170],\n","              [180,   0, 255],[216,   0,   0],[216,   0,  85],[216,   0, 170],[216,   0, 255],[252,   0,   0],[252,   0,  85],\n","              [252,   0, 170],[252,   0, 255]],\n","             [[144,  36,   0],[144,  36,  85],[144,  36, 170],[144,  36, 255],[180,  36,   0],[180,  36,  85],[180,  36, 170],\n","              [180,  36, 255],[216,  36,   0],[216,  36,  85],[216,  36, 170],[216,  36, 255],[252,  36,   0],[252,  36,  85],\n","              [252,  36, 170],[252,  36, 255]],\n","             [[144,  72,   0],[144,  72,  85],[144,  72, 170],[144,  72, 255],[180,  72,   0],[180,  72,  85],[180,  72, 170],\n","              [180,  72, 255],[216,  72,   0],[216,  72,  85],[216,  72, 170],[216,  72, 255],[252,  72,   0],[252,  72,  85],\n","              [252,  72, 170],[252,  72, 255]],\n","             [[144, 108,   0],[144, 108,  85],[144, 108, 170],[144, 108, 255],[180, 108,   0],[180, 108,  85],[180, 108, 170],\n","              [180, 108, 255],[216, 108,   0],[216, 108,  85],[216, 108, 170],[216, 108, 255],[252, 108,   0],[252, 108,  85],\n","              [252, 108, 170],[252, 108, 255]],\n","             [[144, 144,   0],[144, 144,  85],[144, 144, 170],[144, 144, 255],[180, 144,   0],[180, 144,  85],[180, 144, 170],\n","              [180, 144, 255],[216, 144,   0],[216, 144,  85],[216, 144, 170],[216, 144, 255],[252, 144,   0],[252, 144,  85],\n","              [252, 144, 170],[252, 144, 255]],\n","             [[144, 180,   0],[144, 180,  85],[144, 180, 170],[144, 180, 255],[180, 180,   0],[180, 180,  85],[180, 180, 170],\n","              [180, 180, 255],[216, 180,   0],[216, 180,  85],[216, 180, 170],[216, 180, 255],[252, 180,   0],[252, 180,  85],\n","              [252, 180, 170],[252, 180, 255]],\n","             [[144, 216,   0],[144, 216,  85],[144, 216, 170],[144, 216, 255],[180, 216,   0],[180, 216,  85],[180, 216, 170],\n","              [180, 216, 255],[216, 216,   0],[216, 216,  85],[216, 216, 170],[216, 216, 255],[252, 216,   0],[252, 216,  85],\n","              [252, 216, 170],[252, 216, 255]],\n","             [[144, 252,   0],[144, 252,  85],[144, 252, 170],[144, 252, 255],[180, 252,   0],[180, 252,  85],[180, 252, 170],\n","              [180, 252, 255],[216, 252,   0],[216, 252,  85],[216, 252, 170],[216, 252, 255],[252, 252,   0],[252, 252,  85],\n","              [252, 252, 170],[255, 255, 255]]])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"38YWlnOMyZsT","colab_type":"code","colab":{}},"source":["## this method will convert a single file to an image \n","## image size (rows x 384) and of the type specified(i.e. grayscale,RGB,BGR or other) and return it\n","\n","def get_image(file_path_to_make_img,**arg):\n","    \n","    with open(file_path_to_make_img,'rb') as file:                        ## reading the file\n","        file_data = file.read()\n","        \n","    length_of_file = len(file_data) ## getting the length\n","    \n","    ## if the image to be of grayscale format\n","    \n","    if(arg['image_format'] == 'grayscale'):\n","        image_grayscale = []\n","        i=0\n","        while(i<length_of_file):   ## traversing over the file\n","            if(file_data[i:i+1] == b'?' or file_data[i:i+1] == b' ' or file_data[i:i+1] == b'\\r' or file_data[i:i+1] == b'\\n'):\n","                i=i+1       ## getting space(' '), enter('\\n'), carridge return('\\r') or uninitialized var('?') we will skip\n","                continue\n","            else:\n","                pixel_value = int(file_data[i:i+2],base=16) ## converting each byte into grayscale value\n","                \n","                i=i+2  ## moving to next byte \n","                \n","                image_grayscale.append([pixel_value]) ## adding pixel value to image_array\n","\n","        image_grayscale = np.array(image_grayscale)                  ## converting image array to numpy array \n","        image_grayscale.resize(image_grayscale.shape[0]//384,384,1)  ## changing shape of my image to (rows x 384)(width is fixed)\n","        \n","        return arg['image_format'],image_grayscale                                       #returning the image and its format\n","    \n","   ## if the image is to be of RGB format  \n","    \n","    elif(arg['image_format'] == 'RGB'):\n","        image_RGB = []\n","        i=0\n","        while(i<length_of_file):           ## traversing over the file\n","            if(file_data[i:i+1] == b'?' or file_data[i:i+1] == b' ' or file_data[i:i+1] == b'\\r' or file_data[i:i+1] == b'\\n'):\n","                i=i+1      ## getting space(' '), enter('\\n'), carridge return('\\r') or uninitialized var('?') we will skip\n","                continue\n","            else:\n","                x,y = 0,0\n","                if(file_data[i+1:i+2] == b' '):\n","                    x = int(file_data[i:i+1],base=16)   ##getting x_coordinate of map\n","                    y = int(b'0',base=16) ##getting y_coordinate of map\n","                else:\n","                    x = int(file_data[i:i+1],base=16)   ##getting x_coordinate of map\n","                    y = int(file_data[i+1:i+2],base=16) ##getting y_coordinate of map\n","                    \n","                i=i+2   ## moving to next byte\n","                \n","                pixel_value = color_map[x][y]  ##getting color from the map \n","                \n","                image_RGB.append(pixel_value) ## adding pixel_value in image_array\n","                \n","                \n","                \n","        image_RGB = np.array(image_RGB)                   ## converting image array to numpy array \n","        image_RGB.resize(image_RGB.shape[0]//384,384,3)   ## setting the width to 384\n","        \n","        return arg['image_format'],image_RGB                                       #returning the image and its format\n","    \n","    ## if the image is to be of HSV format\n","    \n","    elif(arg['image_format'] == 'HSV'):\n","        image_HSV = []\n","        i=0\n","        while(i<length_of_file):         ## traversing over the file\n","            if(file_data[i:i+1] == b'?' or file_data[i:i+1] == b' ' or file_data[i:i+1] == b'\\r' or file_data[i:i+1] == b'\\n'):\n","                i=i+1        ## getting space(' '), enter('\\n'), carridge return('\\r') or uninitialized var('?') we will skip\n","                continue\n","            else:\n","                x,y = 0,0\n","                if(file_data[i+1:i+2] == b' '):\n","                    x = int(file_data[i:i+1],base=16)   ##getting x_coordinate of map\n","                    y = int(b'0',base=16) ##getting y_coordinate of map\n","                else:\n","                    x = int(file_data[i:i+1],base=16)   ##getting x_coordinate of map\n","                    y = int(file_data[i+1:i+2],base=16) ##getting y_coordinate of map\n","                \n","                i=i+2   ## moving to next byte\n","                \n","                pixel_value_RGB = color_map[x][y]   ##getting color from the map \n","                \n","                R,G,B = pixel_value_RGB/255                     ## sacled RGB values from 0 to 1\n","\n","                #for V value in HSV\n","                V = max(R,G,B)\n","\n","                #for Saturation(S) value in HSV\n","                S = 0.0\n","                if(V == 0):\n","                    S = 0\n","                else:\n","                    S = (V-min(R,G,B))/V\n","\n","                #for Hue(H) value in HSV\n","                H = 0.0\n","                if(V==min(R,G,B)):\n","                    H=0\n","                elif(V==R):\n","                    H = 60*(G-B)/(V - min(R,G,B))\n","                elif(V==G):\n","                    H = 60*(B-R)/(V - min(R,G,B)) + 120\n","                elif(V==B):\n","                    H = 60*(R-G)/(V - min(R,G,B)) + 240 \n","                if(H<0.0): \n","                    H = H + 360\n","\n","\n","                pixel_value_HSV = [H/2,S*255,V*255] ## getting HSV pixel_value\n","                \n","                image_HSV.append(pixel_value_HSV)                 ## adding pixel_value to the image\n","        \n","        image_HSV = np.array(image_HSV,dtype='uint8')            ## converting image array to numpy array \n","        image_HSV.resize(image_HSV.shape[0]//384,384,3)          ## setting the width to 384\n","                     \n","        return arg['image_format'],image_HSV            #returning the image and its format\n","    \n","    ## if the image is to be of BGR format  \n","    \n","    elif(arg['image_format'] == 'BGR'):\n","        image_BGR = []\n","        i=0\n","        while(i<length_of_file):                        ## traversing over the file\n","            if(file_data[i:i+1] == b'?' or file_data[i:i+1] == b' ' or file_data[i:i+1] == b'\\r' or file_data[i:i+1] == b'\\n'):\n","                i=i+1      ## getting space(' '), enter('\\n'), carridge return('\\r') or uninitialized var('?') we will skip\n","                continue\n","            else:\n","                x,y = 0,0 \n","                if(file_data[i+1:i+2] == b' '):\n","                    x = int(file_data[i:i+1],base=16)   ##getting x_coordinate of map\n","                    y = int(b'0',base=16) ##getting y_coordinate of map\n","                else:\n","                    x = int(file_data[i:i+1],base=16)   ##getting x_coordinate of map\n","                    y = int(file_data[i+1:i+2],base=16) ##getting y_coordinate of map\n","                \n","                i=i+2   ## moving to next byte\n","                \n","                R,G,B = color_map[x][y]      ## getting colours (RGB) from map\n","                \n","                pixel_value = [B,G,R]   ## geting BGR pixel\n","                \n","                image_BGR.append(pixel_value)  ## adding pixel_value to image_array\n","    \n","        image_BGR = np.array(image_BGR)                   ## converting image array to numpy array \n","        image_BGR.resize(image_BGR.shape[0]//384,384,3)   ## setting the width to 384\n","        \n","        return arg['image_format'],image_BGR                                       #returning the image and its format\n","    \n","    ## if the image is to be of RGB1 format\n","    \n","    elif(arg['image_format'] == 'RGB1'):\n","        image_RGB1 = []\n","        i=0\n","        while(i<length_of_file):                        ## traversing over the file\n","            if(file_data[i:i+1] == b'?' or file_data[i:i+1] == b' ' or file_data[i:i+1] == b'\\r' or file_data[i:i+1] == b'\\n'):\n","                i=i+1         ## getting space(' '), enter('\\n'), carridge return('\\r') or uninitialized var('?') we will skip\n","                continue\n","            else:\n","                pixel_value_binary = format(int(bin(int(file_data[i:i+2],base=16))[2:],base=10),'08') \n","                                                                            ## converting byte value into binary  \n","                \n","                i=i+2   ## moving to next byte\n","                \n","                r = int(pixel_value_binary[0:3], base=2)             ## first 3 bits for r\n","                g = int(pixel_value_binary[3:6], base=2)           ## second 3 bits for g\n","                b = int(pixel_value_binary[6:8], base = 2)         ## last 2 bits for b\n","                \n","                pixel_value = [r*16, g*16 , b*32]  ## getting pixel value\n","                \n","                image_RGB1.append(pixel_value)     ## adding pixel value in image_array\n","    \n","        image_RGB1 = np.array(image_RGB1)                   ## converting image array to numpy array \n","        image_RGB1.resize(image_RGB1.shape[0]//384,384,3)   ## setting the width to 384\n","        \n","        return arg['image_format'],image_RGB1                                       #returning the image and its format\n","    \n","    ## if the image is to be in RGB2 format \n","    \n","    elif(arg['image_format'] == 'RGB2'):\n","        image_RGB2 = []\n","        i=0\n","        while(i<length_of_file):                            ## traversing over the file\n","            if(file_data[i:i+1] == b'?' or file_data[i:i+1] == b' ' or file_data[i:i+1] == b'\\r' or file_data[i:i+1] == b'\\n'):\n","                i=i+1          ## getting space(' '), enter('\\n'), carridge return('\\r') or uninitialized var('?') we will skip\n","                continue\n","            else:\n","                pixel_value = int(file_data[i:i+2],base=16)  ## getting pixel value\n","                i=i+2 ## moving to next byte\n","                image_RGB2.append([pixel_value]*3)   ## multiplying the channels\n","\n","        image_RGB2 = np.array(image_RGB2)                  ## converting image array to numpy array \n","        image_RGB2.resize(image_RGB2.shape[0]//384,384,3)  ## changing shape of my image to (rows x 384)(width is fixed)\n","        \n","        return arg['image_format'],image_RGB2                                       #returning the image and its format"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZOorr2IvyZsV","colab_type":"code","colab":{}},"source":["## getting images for all the files and saving them\n","\n","import numpy as np\n","import cv2\n","import glob\n","\n","def make_image_of_binary(path_folder_having_binary_file, class_folder_name, **arg):\n","    \n","    ## path of the folder from which we want to save the image with and without offset\n","\n","    folder_path_to_save_RGB_image_with_offset = r\"E:\\project malware detection\\converted images\\converted images with offset\" + class_folder_name +\"\\RGB with offset\\\\\"\n","    folder_path_to_save_RGB_image_without_offset = r\"E:\\project malware detection\\converted images\\converted images without offset\" + class_folder_name +\"\\RGB without offset\\\\\"\n","\n","    folder_path_to_save_grayscale_img_with_offset = r\"E:\\project malware detection\\converted images\\converted images with offset\" + class_folder_name +\"\\grayscale with offset\\\\\"\n","    folder_path_to_save_grayscale_img_without_offset = r\"E:\\project malware detection\\converted images\\converted images without offset\" + class_folder_name +\"\\grayscale without offset\\\\\"\n","\n","    folder_path_to_save_HSV_image_with_offset = r\"E:\\project malware detection\\converted images\\converted images with offset\" + class_folder_name +\"\\HSV with offset\\\\\"\n","    folder_path_to_save_HSV_image_without_offset = r\"E:\\project malware detection\\converted images\\converted images without offset\" + class_folder_name +\"\\HSV without offset\\\\\"\n","\n","    folder_path_to_save_BGR_image_with_offset = r\"E:\\project malware detection\\converted images\\converted images with offset\" + class_folder_name +\"\\BGR with offset\\\\\"\n","    folder_path_to_save_BGR_image_without_offset = r\"E:\\project malware detection\\converted images\\converted images without offset\" + class_folder_name +\"\\BGR without offset\\\\\"\n","\n","    folder_path_to_save_RGB1_image_with_offset = r\"E:\\project malware detection\\converted images\\converted images with offset\" + class_folder_name +\"\\RGB1 with offset\\\\\"\n","    folder_path_to_save_RGB1_image_without_offset = r\"E:\\project malware detection\\converted images\\converted images without offset\" + class_folder_name +\"\\RGB1 without offset\\\\\"\n","\n","    folder_path_to_save_RGB2_image_with_offset = r\"E:\\project malware detection\\converted images\\converted images with offset\" + class_folder_name +\"\\RGB2 with offset\\\\\"\n","    folder_path_to_save_RGB2_image_without_offset = r\"E:\\project malware detection\\converted images\\converted images without offset\" + class_folder_name +\"\\RGB2 without offset\\\\\"\n","\n","    ##getting list of all the files to be converted to image \n","    \n","    list_binary_files_to_be_converted_to_image = glob.glob(path_folder_having_binary_file + class_folder_name + '\\*')\n","                                                            \n","    print(\"Converting binary_txt's to image.......\")\n","    \n","    for file in list_binary_files_to_be_converted_to_image:\n","        img_format,img = get_image(file, image_format = arg['img_format'])     ## set show_ing = True only when you have to view single img \n","                                                                                                ## image_format to be specified(RGB OR grayscale or any other)\n","        file_name = file.split('\\\\')[-1].split('.')[0]\n","        if(arg['offset'] == True):   ## for saving image with offset\n","            if(img_format == 'grayscale'):\n","                cv2.imwrite(folder_path_to_save_grayscale_img_with_offset + file_name + 'gray.jpg',img)     ##saving the grayscale image with_offset\n","            elif(img_format == 'RGB'):\n","                cv2.imwrite(folder_path_to_save_RGB_image_with_offset + file_name + 'RGB.jpg',img)     ##saving the RGB image with_offset\n","            elif(img_format == 'HSV'):\n","                cv2.imwrite(folder_path_to_save_HSV_image_with_offset + file_name + 'HSV.jpg',img)     ##saving the HSV image with_offset\n","            elif(img_format == 'BGR'):\n","                cv2.imwrite(folder_path_to_save_BGR_image_with_offset + file_name + 'BGR.jpg',img)     ##saving the BGR image with_offset\n","            elif(img_format == 'RGB1'):\n","                cv2.imwrite(folder_path_to_save_RGB1_image_with_offset + file_name + 'RGB1.jpg',img)     ##saving the RGB1 image with_offset\n","            elif(img_format == 'RGB2'):\n","                cv2.imwrite(folder_path_to_save_RGB2_image_with_offset + file_name + 'RGB2.jpg',img)     ##saving the RGB1 image with_offset\n","        \n","        elif(arg['offset'] == False):  ## for saving image without offset\n","            if(img_format == 'grayscale'):\n","                cv2.imwrite(folder_path_to_save_grayscale_img_without_offset + file_name + 'gray.jpg',img)     ##saving the grayscale image without_offset \n","            elif(img_format == 'RGB'):\n","                cv2.imwrite(folder_path_to_save_RGB_image_without_offset + file_name + 'RGB.jpg',img)     ##saving the RGB image without_offset\n","            elif(img_format == 'HSV'):\n","                cv2.imwrite(folder_path_to_save_HSV_image_without_offset + file_name + 'HSV.jpg',img)     ##saving the HSV image without_offset\n","            elif(img_format == 'BGR'):\n","                cv2.imwrite(folder_path_to_save_BGR_image_without_offset + file_name + 'BGR.jpg',img)     ##saving the BGR image without_offset\n","            elif(img_format == 'RGB1'):\n","                cv2.imwrite(folder_path_to_save_RGB1_image_without_offset + file_name + 'RGB1.jpg',img)     ##saving the RGB1 image without_offset\n","            elif(img_format == 'RGB2'):\n","                cv2.imwrite(folder_path_to_save_RGB2_image_without_offset + file_name + 'RGB2.jpg',img)     ##saving the RGB1 image without_offset\n","        \n","    print(\"Converting binary_txt's to image Complete.......\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZTQh_orfyZsX","colab_type":"code","colab":{}},"source":["## path of the folder from which we want to load the binary file with and without offset\n","\n","path_folder_having_binary_file_with_offset = r'E:\\project malware detection\\txt malware files\\txt malware files with offset'\n","path_folder_having_binary_file_without_offset = r'E:\\project malware detection\\txt malware files\\txt malware files without offset'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-70Sr5VNyZsa","colab_type":"code","colab":{}},"source":["##calling functions and making images of the binary files with and without offset\n","\n","folder_of_class_to_be_converted_to_img = '\\class1'\n","img_fmt = 'HSV'\n","\n","make_image_of_binary(path_folder_having_binary_file_with_offset, folder_of_class_to_be_converted_to_img, img_format = img_fmt, offset = True)\n","\n","make_image_of_binary(path_folder_having_binary_file_without_offset, folder_of_class_to_be_converted_to_img, img_format = img_fmt, offset = False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lL8kcctRyZsc","colab_type":"text"},"source":["# collecting image and making dataset as pickle file\n"]},{"cell_type":"code","metadata":{"id":"kZ59oOmuyZsd","colab_type":"code","colab":{}},"source":["def save_dataset(X_data, Y_data, folder_to_save_dataset, image_format_to_use):\n","    \n","    with open(folder_to_save_dataset + r'\\X_data ' + image_format_to_use + '.pickle', 'wb') as file:  ## saving X_data\n","        pickle.dump(X_data, file)\n","    \n","    with open(folder_to_save_dataset + r'\\Y_data ' + image_format_to_use + '.pickle', 'wb') as file:  ## saving Y_data\n","        pickle.dump(Y_data, file)\n","    \n","    return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FjLA64kvyZsf","colab_type":"code","colab":{}},"source":["def get_X_and_Y(all_image_with_label_array):\n","    x=[]\n","    y=[]\n","    \n","    for image,Class in all_image_with_label_array:\n","        x.append(image)                             ## seperating the tupple and making list of X_data and Y_data\n","        y.append(Class)\n","    \n","    x = np.array(x)\n","    y = np.array(y)\n","    \n","    return x, y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dHuKgfr1yZsh","colab_type":"code","colab":{}},"source":["def get_image_array(class_folder_path, Class, image_format_to_use):\n","    IMG_SIZE = 32  ## image sisze in which images is to be resized\n","    \n","    image_list = glob.glob(class_folder_path + r'\\\\' + image_format_to_use + '\\*') \n","                                                        ## getting list of all images in a class folder\n","    \n","    image_array_with_labels = []\n","    \n","    for image in image_list:                    ## importing image and resizeing it and adding tuple in image_array_with_labels\n","        img = cv2.imread(image)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n","        image_array_with_labels.append((img,Class))\n","    \n","    return image_array_with_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m6cZcWZYyZsj","colab_type":"code","colab":{}},"source":["import glob\n","import cv2\n","import random\n","import numpy as np\n","import pickle\n","\n","def get_dataset(cvt_images_path,image_format_to_use, folder_to_save_dataset):\n","    \n","    print('Saving Dataset.....')\n","    \n","    class_folders_list = glob.glob(cvt_images_path + '\\*') ## getting list of class folders\n","    \n","    total_classes = [i for i in range(len(class_folders_list))] ## no. of folder = total class and assigning no. to each folder\n","    \n","    all_image_with_label_array = []\n","    \n","    for Class in total_classes:\n","        image_array_with_label = get_image_array(class_folders_list[Class], Class, image_format_to_use) \n","                                                    ## array of images with class .... list of tuple ..... (image, image_class)\n","                                                                               \n","        for image_class_tupple in image_array_with_label:\n","            all_image_with_label_array.append(image_class_tupple) \n","                                                    ## adding tuples(image, label) to all_image_with_label_array\n","\n","    random.shuffle(all_image_with_label_array) \n","                                                ## shuffling the data\n","    \n","    X_data, Y_data = get_X_and_Y(all_image_with_label_array) \n","                                                ## getting X and Y as np array from all_image_with_label_array(list of tuples)\n","    \n","    save_dataset(X_data, Y_data, folder_to_save_dataset, image_format_to_use) \n","                                                ## saving np array of images and their respective labels\n","    \n","    print('Saving Dataset Complete.....')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aAdmv5L5yZsl","colab_type":"code","outputId":"e016a71f-7a63-4718-9b7c-19218a151fe2","colab":{}},"source":["#path of folder having images stored\n","cvt_images_path = r'E:\\project malware detection\\converted images\\converted images with offset'\n","\n","# path of folder to asve dataset\n","folder_to_save_dataset = r'E:\\project malware detection\\dataset'\n","\n","# image format to be used\n","image_format_to_use = r'RGB with offset'\n","\n","## calling get_dataset function and getting getting our dataset saved so that we do not have to import images again and again\n","\n","\n","get_dataset(cvt_images_path,image_format_to_use,folder_to_save_dataset)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Saving Dataset.....\n","Saving Dataset Complete.....\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vXr8JnGc_Cn2","colab_type":"text"},"source":["# Mounting Drive\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"VVPUxRFH-9Tp","colab_type":"code","outputId":"04d9de2d-99ea-462f-8745-9c37738b1912","executionInfo":{"status":"ok","timestamp":1591007453926,"user_tz":-330,"elapsed":76611,"user":{"displayName":"Divyansh Chauhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0xnQlq6-YYMuSBp_u1tB6I3zku6_o4AdJmOt9Nw=s64","userId":"11794048624609588207"}},"colab":{"base_uri":"https://localhost:8080/","height":120}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6iaKsEEzz4DB","colab_type":"text"},"source":["# Loading Dataset\n"]},{"cell_type":"code","metadata":{"id":"eBZQnFPkyZso","colab_type":"code","colab":{}},"source":["import pickle\n","\n","image_format_to_use = r'RGB with offset'\n","\n","with open(r'/content/drive/My Drive/malware dataset/X_data RGB with offset.pickle', 'rb') as file:\n","        x = pickle.load(file)\n","with open(r'/content/drive/My Drive/malware dataset/Y_data RGB with offset.pickle', 'rb') as file:\n","        y = pickle.load(file)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vb3xKC5jyZsq","colab_type":"code","outputId":"e4acd052-a907-4a0f-e84f-e329766003ac","executionInfo":{"status":"ok","timestamp":1591007493615,"user_tz":-330,"elapsed":2212,"user":{"displayName":"Divyansh Chauhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0xnQlq6-YYMuSBp_u1tB6I3zku6_o4AdJmOt9Nw=s64","userId":"11794048624609588207"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["y.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3683,)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"z_ciYIKc0BeH","colab_type":"text"},"source":["# Training CNN Model"]},{"cell_type":"code","metadata":{"id":"O8Ponb0OyZss","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LZlhk2yGyZsu","colab_type":"code","colab":{}},"source":["from sklearn import model_selection"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GhVi5WKkyZsx","colab_type":"code","colab":{}},"source":["x_train ,x_test , y_train, y_test = model_selection.train_test_split(x,y, random_state = 0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5cckRKflyZsz","colab_type":"code","outputId":"31afbf81-cc79-457e-f951-307d27c11220","executionInfo":{"status":"ok","timestamp":1591008879779,"user_tz":-330,"elapsed":1261,"user":{"displayName":"Divyansh Chauhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0xnQlq6-YYMuSBp_u1tB6I3zku6_o4AdJmOt9Nw=s64","userId":"11794048624609588207"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["x_train ,x_test = x_train/255 ,x_test/255 \n","y_train.shape,y_test.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((2762,), (921,))"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"M0YKIJ1_yZs3","colab_type":"code","outputId":"b802e033-9b65-422e-de4c-587a2b43b3c3","executionInfo":{"status":"ok","timestamp":1591008893391,"user_tz":-330,"elapsed":11458,"user":{"displayName":"Divyansh Chauhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0xnQlq6-YYMuSBp_u1tB6I3zku6_o4AdJmOt9Nw=s64","userId":"11794048624609588207"}},"colab":{"base_uri":"https://localhost:8080/","height":368}},"source":["model = Sequential()\n","\n","model.add(Conv2D(16, (3,3), activation = 'relu', padding = 'same', input_shape = (32,32,3)))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","model.add(Conv2D(32, (3,3), activation = 'relu', padding = 'same'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","#model.add(Conv2D(64, (3,3), activation = 'relu', padding = 'same'))\n","#model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","model.add(Flatten())\n","\n","model.add(Dense(units = 2000))\n","\n","model.add(Dense(units = 1024, activation = 'relu'))\n","\n","model.add(Dense(units = 128, activation = 'relu'))\n","\n","model.add(Dense(units = 1, activation = 'sigmoid'))\n","\n","model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","\n","model.fit(x_train, y_train, epochs = 10, batch_size = 20)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","2762/2762 [==============================] - 1s 402us/step - loss: 0.4256 - accuracy: 0.8077\n","Epoch 2/10\n","2762/2762 [==============================] - 1s 335us/step - loss: 0.1858 - accuracy: 0.9319\n","Epoch 3/10\n","2762/2762 [==============================] - 1s 336us/step - loss: 0.1478 - accuracy: 0.9453\n","Epoch 4/10\n","2762/2762 [==============================] - 1s 329us/step - loss: 0.1060 - accuracy: 0.9605\n","Epoch 5/10\n","2762/2762 [==============================] - 1s 334us/step - loss: 0.0820 - accuracy: 0.9710\n","Epoch 6/10\n","2762/2762 [==============================] - 1s 330us/step - loss: 0.0686 - accuracy: 0.9776\n","Epoch 7/10\n","2762/2762 [==============================] - 1s 333us/step - loss: 0.0583 - accuracy: 0.9797\n","Epoch 8/10\n","2762/2762 [==============================] - 1s 331us/step - loss: 0.0667 - accuracy: 0.9747\n","Epoch 9/10\n","2762/2762 [==============================] - 1s 331us/step - loss: 0.0484 - accuracy: 0.9848\n","Epoch 10/10\n","2762/2762 [==============================] - 1s 323us/step - loss: 0.0283 - accuracy: 0.9895\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f15ba4337f0>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"6Zs6zrLGyZs5","colab_type":"code","outputId":"ee40a405-7bf7-4018-b2cf-0788989f2145","executionInfo":{"status":"ok","timestamp":1591011021088,"user_tz":-330,"elapsed":2522,"user":{"displayName":"Divyansh Chauhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0xnQlq6-YYMuSBp_u1tB6I3zku6_o4AdJmOt9Nw=s64","userId":"11794048624609588207"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["model.evaluate(x_test, y_test)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["921/921 [==============================] - 0s 99us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.12873614578478515, 0.9554831981658936]"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"hJGWzGbvyZs7","colab_type":"code","outputId":"5bc7a00a-0571-40f5-f80b-6d31cef264bb","executionInfo":{"status":"ok","timestamp":1591011025490,"user_tz":-330,"elapsed":4355,"user":{"displayName":"Divyansh Chauhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0xnQlq6-YYMuSBp_u1tB6I3zku6_o4AdJmOt9Nw=s64","userId":"11794048624609588207"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["predictions = model.predict(x_test)\n","predictions[predictions < 0.5] = 0\n","predictions[predictions >= 0.5] = 1\n","predictions = predictions.reshape(-1).astype('uint8')\n","(predictions == y_test).sum()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["880"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"-ul6msolyZs9","colab_type":"code","colab":{}},"source":["from sklearn.metrics import confusion_matrix, classification_report"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U7D4b4K3yZs_","colab_type":"code","outputId":"53dd323f-7991-4984-f4b4-928a18e4ff03","executionInfo":{"status":"ok","timestamp":1591011034441,"user_tz":-330,"elapsed":2454,"user":{"displayName":"Divyansh Chauhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0xnQlq6-YYMuSBp_u1tB6I3zku6_o4AdJmOt9Nw=s64","userId":"11794048624609588207"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["print(confusion_matrix(y_test, predictions))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[349  33]\n"," [  8 531]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SzY_tU1hyZtC","colab_type":"code","outputId":"b6f2b5a1-c5aa-4c8e-b90f-8b543e939868","executionInfo":{"status":"ok","timestamp":1591011130076,"user_tz":-330,"elapsed":1242,"user":{"displayName":"Divyansh Chauhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0xnQlq6-YYMuSBp_u1tB6I3zku6_o4AdJmOt9Nw=s64","userId":"11794048624609588207"}},"colab":{"base_uri":"https://localhost:8080/","height":167}},"source":["print(classification_report(y_test, predictions))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.98      0.91      0.94       382\n","           1       0.94      0.99      0.96       539\n","\n","    accuracy                           0.96       921\n","   macro avg       0.96      0.95      0.95       921\n","weighted avg       0.96      0.96      0.96       921\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hkt4PjLF08-d","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}